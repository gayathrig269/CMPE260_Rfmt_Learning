{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_MinMaxAlgorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayathrig269/CMPE260_Rfmt_Learning_TicTacToe/blob/main/Part1_MinMaxAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfuijCN92p4C"
      },
      "source": [
        "#Tic-Tac-Toe using Min-Max algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVsrzbFJ2ZPy"
      },
      "source": [
        "In this Notebook, we introduce an agent and then use the Min-Max algorithm to create a computer player which will be able to play a game of Tic Tac Toe.\n",
        "\n",
        "The Min-Max player will always play the best possible move in a given situation. This player will give us a good benchmark to compare the other players against."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhyy-dJC3C8k"
      },
      "source": [
        "#What is Min-Max Agorithm ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouuVtdfa3GNC"
      },
      "source": [
        "Minimax (saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario. When dealing with gains, it is referred to as \"maximin\"—to maximize the minimum gain. Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty. \n",
        "\n",
        "Ref : https://en.wikipedia.org/wiki/Minimax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4q-vFj_3T_M"
      },
      "source": [
        "#Min-Max Player to play Tic-Tac-Toe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV8SRis93klU"
      },
      "source": [
        "Given a board state, we find the best move by simulating all possible continuations from this position and chose the one that is best for our agent. The one best for us is the one with the best outcome if we assume the following points:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6XuT7EB3upw"
      },
      "source": [
        "1.We always make the move that is best for us (Maximizes the game value for us)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLVJivXc3xq-"
      },
      "source": [
        "2.Our opponent always makes the move that is best for them (and thus worst for us — Minimizing the game value for us)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Itjjo9J4D1v"
      },
      "source": [
        "#The Min-Max Player Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZtBWVQG4HlI"
      },
      "source": [
        "Our code contains 2 player classes which implement the Min Max algorithm for playing Tic Tac Toe:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EFyQoJV4R0z"
      },
      "source": [
        "1. MinMaxAgent.py\n",
        "    \n",
        "Plays Tic Tac Toe using the Min Max Algorithm in a deterministic way. i.e. if there is more than 1 move with equal best scores in a given position, this player will always chose the same move."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tmv8LI94dvU"
      },
      "source": [
        "2. RndMinMaxAgent.py: \n",
        "\n",
        "Plays Tic Tac Toe using the Min Max Algorithm in a non-deterministic way. I.e. if there is more than 1 move with equal best scores in a given position this player will each time randomly chose between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4HF5TEy4FVP"
      },
      "source": [
        "In order to make things a bit more efficient, the players will also store the value for a given board position in an internal cache. This means, that they only have to compute the possible continuations from each position once. It even makes this first computation more efficient, as often different move combinations will produce the same board positions, which, with the cached result, we don’t have to evaluate again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbMO4Ykyxwmk",
        "outputId": "f05b9ab5-97ee-4809-dc82-fab5f1f1f9a9"
      },
      "source": [
        "#Mounting the google drive contents of TIC-TAC_TOE code \n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/tic_tac_toe_master/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Zj0LQbyENx",
        "outputId": "02720408-d0f3-4899-e38d-c2bb0a8c46bd"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/tic_tac_toe_master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/tic_tac_toe_master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSRazM8JRgzh"
      },
      "source": [
        "#Defining battle function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36AGEh2URfrZ"
      },
      "source": [
        "from Player import Player\n",
        "\n",
        "def battle(player1: Player, player2: Player, num_games: int = 100000):\n",
        "    board = Board()\n",
        "    draw_count = 0\n",
        "    cross_count = 0\n",
        "    naught_count = 0\n",
        "    for _ in range(num_games):\n",
        "        result = play_game(board, player1, player2)\n",
        "        if result == GameResult.CROSS_WIN:\n",
        "            cross_count += 1\n",
        "        elif result == GameResult.NAUGHT_WIN:\n",
        "            naught_count += 1\n",
        "        else:\n",
        "            draw_count += 1\n",
        "\n",
        "    print(\"After {} game we have draws: {}, Player 1 wins: {}, and Player 2 wins: {}.\".format(num_games, draw_count,\n",
        "                                                                                         cross_count, naught_count))\n",
        "\n",
        "    print(\"Which gives percentages of draws: {:.2%}, Player 1 wins: {:.2%}, and Player 2 wins:  {:.2%}\".format(\n",
        "        draw_count / num_games, cross_count / num_games, naught_count / num_games))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvg_EaQ25ZAQ"
      },
      "source": [
        "#Statistics after every battle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bigOcU7Uy5uZ"
      },
      "source": [
        "First we define a small utility function which we call battle to repeatedly pit 2 players against each other for a number of games. After the \"battle\" has finished, the function will return statistics about who won how often."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMAUE2iyy-jj"
      },
      "source": [
        "from Player import Player\n",
        "\n",
        "def battle(player1: Player, player2: Player, num_games: int = 100000):\n",
        "    board = Board()\n",
        "    draw_count = 0\n",
        "    cross_count = 0\n",
        "    naught_count = 0\n",
        "    for _ in range(num_games):\n",
        "        result = play_game(board, player1, player2)\n",
        "        if result == GameResult.CROSS_WIN:\n",
        "            cross_count += 1\n",
        "        elif result == GameResult.NAUGHT_WIN:\n",
        "            naught_count += 1\n",
        "        else:\n",
        "            draw_count += 1\n",
        "\n",
        "    print(\"After {} game we have draws: {}, Player 1 wins: {}, and Player 2 wins: {}.\".format(num_games, draw_count,\n",
        "                                                                                         cross_count, naught_count))\n",
        "\n",
        "    print(\"Which gives percentages of draws: {:.2%}, Player 1 wins: {:.2%}, and Player 2 wins:  {:.2%}\".format(\n",
        "        draw_count / num_games, cross_count / num_games, naught_count / num_games))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1svN0SQzIj8"
      },
      "source": [
        "Let's use this function and to start of with we pit the MinMaxAgent against the RandomPlayer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjkib_Qy1Djz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64aa777-5625-4b20-fd60-95f313a149af"
      },
      "source": [
        "from MinMaxAgent import MinMaxAgent\n",
        "\n",
        "battle(MinMaxAgent(), RandomPlayer())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 100000 game we have draws: 517, Player 1 wins: 99483, and Player 2 wins: 0.\n",
            "Which gives percentages of draws: 0.52%, Player 1 wins: 99.48%, and Player 2 wins:  0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnSrRJS8SF9H"
      },
      "source": [
        "And now, with the Random player going first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk0mbh8ySImF",
        "outputId": "fb7197a2-5c8f-4f9a-9fa1-0043dc243472"
      },
      "source": [
        "battle(RandomPlayer(), MinMaxAgent())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 100000 game we have draws: 19319, Player 1 wins: 0, and Player 2 wins: 80681.\n",
            "Which gives percentages of draws: 19.32%, Player 1 wins: 0.00%, and Player 2 wins:  80.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuSwsFpISPrQ"
      },
      "source": [
        "Next, the 2 MinMax players against each other:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIxTor7hSVaI",
        "outputId": "93359aa8-7b85-4064-fcd6-2ed00ec13b8a"
      },
      "source": [
        "from RndMinMaxAgent import RndMinMaxAgent\n",
        "\n",
        "battle(MinMaxAgent(), RndMinMaxAgent())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 100000 game we have draws: 100000, Player 1 wins: 0, and Player 2 wins: 0.\n",
            "Which gives percentages of draws: 100.00%, Player 1 wins: 0.00%, and Player 2 wins:  0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjO50I-6Sful"
      },
      "source": [
        "Observation:\n",
        "\n",
        "As expected, we got 100% draws."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUcbcHvokswF"
      },
      "source": [
        "1.Min-Max Player vs RandomPlayer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tv79Lqz5q1l",
        "outputId": "32bfcedf-3b6b-4f45-b036-1bd2306797a5"
      },
      "source": [
        "battle(MinMaxAgent(),RandomPlayer(),50000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 50000 game we have draws: 236, Player 1 wins: 49764, and Player 2 wins: 0.\n",
            "Which gives percentages of draws: 0.47%, Player 1 wins: 99.53%, and Player 2 wins:  0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COpt4I8Tk353"
      },
      "source": [
        "Min-Max vs Random player (Min-Max plays second)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GrRAwtA2C7G",
        "outputId": "0823f1dd-f1de-4160-8b04-bf81508922c2"
      },
      "source": [
        "battle(RandomPlayer(), MinMaxAgent(),50000) #50000 is the number of games"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 50000 game we have draws: 9651, Player 1 wins: 0, and Player 2 wins: 40349.\n",
            "Which gives percentages of draws: 19.30%, Player 1 wins: 0.00%, and Player 2 wins:  80.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOIXsIRtk-M8"
      },
      "source": [
        "2.Min-Max Player vs Non-determininstic Min-Max player"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gMEADCp6RJ5",
        "outputId": "46c649ac-fbf1-4038-be42-e01ac8f95ae8"
      },
      "source": [
        "from RndMinMaxAgent import RndMinMaxAgent\n",
        "\n",
        "battle(MinMaxAgent(), RndMinMaxAgent(),50000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 50000 game we have draws: 50000, Player 1 wins: 0, and Player 2 wins: 0.\n",
            "Which gives percentages of draws: 100.00%, Player 1 wins: 0.00%, and Player 2 wins:  0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1NUzqatnjgQ"
      },
      "source": [
        "Min-Max Player vs Non-determininstic Min-Max player\n",
        "\n",
        "Min-Max Player plays second !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOg0Aroxnvgz",
        "outputId": "f501349a-aa9d-4d7c-d872-36c4890835d2"
      },
      "source": [
        "from RndMinMaxAgent import RndMinMaxAgent\n",
        "\n",
        "battle(RndMinMaxAgent(),MinMaxAgent(),50000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 50000 game we have draws: 50000, Player 1 wins: 0, and Player 2 wins: 0.\n",
            "Which gives percentages of draws: 100.00%, Player 1 wins: 0.00%, and Player 2 wins:  0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXxypsQjfcjq"
      },
      "source": [
        "Observation:\n",
        "\n",
        "As expected, when MinMax player can't outdo itself. It draws everytime whether it plays first or second."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WBGes17oMbu"
      },
      "source": [
        "#Plotting graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQwM11rjtlI"
      },
      "source": [
        "Defining **eval_players** function : \n",
        "\n",
        "\n",
        "Helps in plotting a graph to analyze two players fighting a battle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MFJCYwe2cOk"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import util\n",
        "\n",
        "def eval_players(p1 : Player, p2 : Player, num_battles : int, games_per_battle = 100, loc='best'):\n",
        "    p1_wins = []\n",
        "    p2_wins = []\n",
        "    draws = []\n",
        "    count = []    \n",
        "\n",
        "    for i in range(num_battles):\n",
        "        p1win, p2win, draw = battle(p1, p2, games_per_battle, True)\n",
        "        p1_wins.append(p1win*100.0/games_per_battle)\n",
        "        p2_wins.append(p2win*100.0/games_per_battle)\n",
        "        draws.append(draw*100.0/games_per_battle)\n",
        "        count.append(i*games_per_battle)\n",
        "        p1_wins.append(p1win*100.0/games_per_battle)\n",
        "        p2_wins.append(p2win*100.0/games_per_battle)\n",
        "        draws.append(draw*100.0/games_per_battle)\n",
        "        count.append((i+1)*games_per_battle)\n",
        "\n",
        "    plt.ylabel('Game outcomes in %')\n",
        "    plt.xlabel('Game number')\n",
        "\n",
        "    plt.plot(count, draws, 'r-', label='Draw')\n",
        "    plt.plot(count, p1_wins, 'g-', label='Player 1 wins')\n",
        "    plt.plot(count, p2_wins, 'b-', label='Player 2 wins')\n",
        "    plt.legend(loc=loc, shadow=True, fancybox=True, framealpha =0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n9AWR7ooQ9Z"
      },
      "source": [
        "Testing MinMax Agent vs RandomMinMax agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QUZ6Y7k6daE"
      },
      "source": [
        "player1 = MinMaxAgent()\n",
        "player2 = RndMinMaxAgent()\n",
        "eval_players(player1,player2,100)\n",
        "#100 is the no. of battles\n",
        "#1 battle = 100 games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwtBw-2Xo8ni"
      },
      "source": [
        "player1 = RndMinMaxAgent()\n",
        "player2 = MinMaxAgent()\n",
        "eval_players(player1, player2,100)\n",
        "#100 is the no. of battles\n",
        "#1 battle = 100 games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRXatUL7gIn9"
      },
      "source": [
        "Observation: \n",
        "\n",
        "As seen in the battle function statistics, although they play for 10000 games, they neither win/lose.It's a draw 100% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTL-CWakduU"
      },
      "source": [
        "2.Min-Max Player vs Random Player"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5RaNatX5zq4"
      },
      "source": [
        "player1 = MinMaxAgent()\n",
        "player2 = RandomPlayer()\n",
        "eval_players(player1, player2,5)\n",
        "#5 is the number of battles\n",
        "#total 500 games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWaCKB91rIz9"
      },
      "source": [
        "player1 = RandomPlayer()\n",
        "player2 = MinMaxAgent()\n",
        "eval_players(player1, player2,5)\n",
        "#5 is the number of battles\n",
        "#total 500 games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z65ODohrOu7"
      },
      "source": [
        "Observation: \n",
        "\n",
        "Min-Max agent wins the game, 99% of the time when it starts first, and when playing second, it wins 80% of the games, but draws at random places of games."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6eLm1lrmY8"
      },
      "source": [
        "#Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWMLkKoFs0rV"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWEdwQ7ss-wG"
      },
      "source": [
        "From the above table, it can be concluded as, in order to be considered as  playing better than a pure random player, a player should achieve significantly more than 20% draws against a Min-Max player when going first and significantly more than 1% draws when going second."
      ]
    }
  ]
}